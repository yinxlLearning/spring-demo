# Use root/example as user/password credentials

services:
  mysql:
    image: mysql:8.0.43
    container_name: my-mysql       # 自定义容器名（可选）
    restart: always                # 自动重启策略
    environment:
      MYSQL_ROOT_PASSWORD: Yinxl_123     # root 密码
      MYSQL_DATABASE: test               # 初始化数据库
      MYSQL_USER: yinxl                  # 新建普通用户
      MYSQL_PASSWORD: Yinxl_123         # 普通用户密码
    ports:
      - "3306:3306"               # 映射端口
    volumes:
      - ./mysql/data:/var/lib/mysql       # 挂载数据目录（持久化）
      - ./mysql/conf:/etc/mysql/conf.d    # 挂载配置文件
      - ./mysql/init:/docker-entrypoint-initdb.d  # 初始化 SQL 脚本
    networks:
      - backend
  redis:
    image: redis:7.4.5
    container_name: my-redis       # 自定义容器名（可选）
    restart: always                # 自动重启策略
    ports:
      - "6379:6379"               # 映射端口
    volumes:
      - ./redis/data:/data         # 挂载数据目录（持久化）
      - ./redis/conf/redis.conf:/usr/local/etc/redis/redis.conf  # 挂载配置文件
    command: ["redis-server", "/usr/local/etc/redis/redis.conf"]  # 使用自定义配置启动 Redis
    networks:
      - backend
  nacos:
    image: nacos/nacos-server:v2.4.3
    container_name: nacos-standalone
    environment:
      - PREFER_HOST_MODE=hostname
      - MODE=standalone
      - NACOS_AUTH_IDENTITY_KEY=serverIdentity
      - NACOS_AUTH_IDENTITY_VALUE=security
      - NACOS_AUTH_TOKEN=SecretKey012345678901234567890123456789012345678901234567890123456789
    volumes:
      - ./standalone-logs/:/home/nacos/logs
    ports:
      - "8848:8848"
      - "9848:9848"
    networks:
      - backend
  kafdrop:
    # 访问地址 http://localhost:19000/
    # 轻量级 Kafka Web UI
    # 容器内访问容器名来访问对应服务
    image: obsidiandynamics/kafdrop
    container_name: my-kafdrop
    restart: always
    ports:
      - "19000:9000"
    environment:
      KAFKA_BROKERCONNECT: my-kafka:9092
    depends_on:
      - kafka
    networks:
      - backend
  kafka:
    # 数据在 /var/lib/kafka/data
    # 安装目录在 /opt/kafka
    image: apache/kafka:latest
    container_name: my-kafka
    restart: always
    ports:
      - "19092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@my-kafka:9093
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    networks:
      - backend
  zookeeper:
    image: zookeeper:3.9        # 使用官方 Zookeeper 镜像，指定版本 3.9，避免 latest 版本不稳定
    container_name: my-zookeeper  # 容器名称，方便宿主机管理，例如 docker logs my-zookeeper
    restart: always             # 容器退出时自动重启
    ports:
      - "12181:2181"             # 将宿主机端口 2181 映射到容器端口 2181，客户端可以通过 localhost:2181 访问 Zookeeper
    environment:
      # Zookeeper 节点 ID，单节点也必须设置，集群中用于区分不同节点
      ZOO_MY_ID: 1
      # Zookeeper 客户端监听端口，默认 2181 ，Zookeeper 对外提供服务的客户端端口，客户端（如 Kafka 或 zkCli.sh）通过此端口连接
      ZOO_PORT: 2181
      # 是否启用客户端端口，如果设置为 "no"，客户端将无法连接 Zookeeper
      ZOO_ENABLE_CLIENT_PORT: "yes"
      # 集群节点信息格式：server.<id>=<host>:<peerPort>:<leaderElectionPort>
      # 单节点模式也需要配置，peerPort=2888, leaderElectionPort=3888（不会实际用到）
      # server.<id>=<主机名或IP>:<集群通信端口>:<选举端口>;<客户端端口>
      ZOO_SERVERS: server.1=localhost:2888:3888;2181
    volumes:
      - ./zookeeper/data:/data
      - ./zookeeper/datalog:/datalog
    networks:
      - backend
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0  # 官方 Elasticsearch 镜像（指定版本，避免使用 latest）
    container_name: my-elasticsearch      # 容器名称，方便通过 docker logs / docker exec 管理
    restart: always
    environment:
      - node.name=es-node        # 节点名称，用于标识 ES 节点（集群中必须唯一）
      - cluster.name=es-cluster  # 集群名称（多个节点时必须一致）
      - discovery.type=single-node  # 设置为单节点模式，避免 ES 启动时尝试寻找其他节点
      - bootstrap.memory_lock=true   # 锁定内存，防止 JVM 堆被 swap 到磁盘，提升性能
      - xpack.security.enabled=false # 关闭 x-pack 安全认证（生产环境建议开启，否则 Kibana 需要用户名密码）
      - ES_JAVA_OPTS=-Xms1g -Xmx1g   # JVM 内存参数，Xms 初始堆大小，Xmx 最大堆大小（这里分配 1GB）
    ulimits:
      memlock:    # ulimits 限制，用来控制容器的资源
        soft: -1  # 软限制，-1 表示无限制
        hard: -1  # 硬限制，-1 表示无限制
    volumes:
      - ./es/data:/usr/share/elasticsearch/data   # 挂载数据目录，实现数据持久化
      - ./es/logs:/usr/share/elasticsearch/logs   # 挂载日志目录，方便查看日志
    ports:
      - "9200:9200"   # 对外暴露 REST API 端口，客户端和 Kibana 通过 http://localhost:9200 访问
      - "9300:9300"   # ES 集群通信端口（用于节点间通信，单机模式下不会用到）
    networks:
      - backend
  kibana:
    image: docker.elastic.co/kibana/kibana:8.15.0  # 官方 Kibana 镜像
    container_name: my-kibana   # Kibana 容器名称
    restart: always
    environment:
      - ELASTICSEARCH_HOSTS=http://my-elasticsearch:9200  # Kibana 连接的 Elasticsearch 地址（用服务名而不是 localhost）
    ports:
      - "15601:5601"   # 对外暴露 Kibana Web UI 端口，通过 http://localhost:5601 访问
    depends_on:
      - elasticsearch  # 依赖 Elasticsearch，确保 ES 启动后再启动 Kibana
    networks:
      - backend
  postgres:
    image: postgres:15           # 使用官方 PostgreSQL 镜像，指定版本 15，避免使用 latest 导致不兼容
    container_name: my-postgres  # 容器名称，方便使用 docker logs / exec 管理
    restart: always              # 遇到异常退出时自动重启
    ports:
      - "5432:5432"              # 映射端口：宿主机 5432 → 容器 5432
    environment:
      POSTGRES_USER: yinxl       # 数据库用户名（默认是 postgres）
      POSTGRES_PASSWORD: Yinxl_123   # 数据库用户密码（必须设置，否则容器启动失败）
      POSTGRES_DB: test          # 初始化时自动创建的数据库
      TZ: Asia/Shanghai          # 设置时区，避免日志时间和本地不一致
    volumes:
      - ./postgres/data:/var/lib/postgresql/data   # 持久化数据目录，防止容器删除后数据丢失
      - ./postgres/init:/docker-entrypoint-initdb.d # 初始化 SQL 脚本目录（*.sql 或 *.sh 会在容器首次启动时自动执行）
      - ./postgres/conf:/etc/postgresql/conf.d      # 自定义配置文件挂载目录（可选，比如修改 pg_hba.conf 或 postgresql.conf）
    networks:
      - backend
networks:
  backend:
    driver: bridge